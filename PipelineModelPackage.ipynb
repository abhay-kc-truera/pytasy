{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadb3ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/02/25 22:21:04 WARN Utils: Your hostname, Chaturvedi_PC resolves to a loopback address: 127.0.1.1; using 172.31.235.42 instead (on interface eth0)\n",
      "23/02/25 22:21:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/abhay/.ivy2/cache\n",
      "The jars for the packages stored in: /home/abhay/.ivy2/jars\n",
      "org.jpmml#pmml-sparkml added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-5992e9ae-e1b9-400f-8053-dbbaf48c9404;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.jpmml#pmml-sparkml;2.1.0 in central\n",
      "\tfound org.jpmml#pmml-converter;1.5.3 in central\n",
      "\tfound org.jpmml#pmml-model-metro;1.6.3 in central\n",
      "\tfound org.jpmml#pmml-model;1.6.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.13.1 in local-m2-cache\n",
      "\t[2.13.1] com.fasterxml.jackson.core#jackson-annotations;[2.9.4, 2.13.1]\n",
      "\tfound jakarta.xml.bind#jakarta.xml.bind-api;3.0.1 in local-m2-cache\n",
      "\tfound org.glassfish.jaxb#jaxb-runtime;3.0.2 in local-m2-cache\n",
      "\tfound com.sun.activation#jakarta.activation;2.0.1 in local-m2-cache\n",
      "\tfound org.glassfish.jaxb#jaxb-core;3.0.2 in local-m2-cache\n",
      "\tfound com.sun.istack#istack-commons-runtime;4.0.1 in local-m2-cache\n",
      "\tfound com.google.guava#guava;21.0 in local-m2-cache\n",
      "\tfound org.jpmml#pmml-converter-testing;1.5.3 in central\n",
      ":: resolution report :: resolve 4340ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.13.1 from local-m2-cache in [default]\n",
      "\tcom.google.guava#guava;21.0 from local-m2-cache in [default]\n",
      "\tcom.sun.activation#jakarta.activation;2.0.1 from local-m2-cache in [default]\n",
      "\tcom.sun.istack#istack-commons-runtime;4.0.1 from local-m2-cache in [default]\n",
      "\tjakarta.xml.bind#jakarta.xml.bind-api;3.0.1 from local-m2-cache in [default]\n",
      "\torg.glassfish.jaxb#jaxb-core;3.0.2 from local-m2-cache in [default]\n",
      "\torg.glassfish.jaxb#jaxb-runtime;3.0.2 from local-m2-cache in [default]\n",
      "\torg.jpmml#pmml-converter;1.5.3 from central in [default]\n",
      "\torg.jpmml#pmml-converter-testing;1.5.3 from central in [default]\n",
      "\torg.jpmml#pmml-model;1.6.3 from central in [default]\n",
      "\torg.jpmml#pmml-model-metro;1.6.3 from central in [default]\n",
      "\torg.jpmml#pmml-sparkml;2.1.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   1   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-5992e9ae-e1b9-400f-8053-dbbaf48c9404\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/6ms)\n",
      "23/02/25 22:21:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from etl.spark.spark_session_helper import spark\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor ,GBTRegressionModel\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "features = [\n",
    "     'is_male',\n",
    "     'batter_runs_30D',\n",
    "     'batter_runs_90D',\n",
    "     'batter_runs_300D',\n",
    "     'batter_runs_1000D',\n",
    "     'batter_runs_1000D_venue',\n",
    "     'balls_faced_30D',\n",
    "     'balls_faced_90D',\n",
    "     'balls_faced_300D',\n",
    "     'balls_faced_1000D',\n",
    "     'balls_faced_1000D_venue',\n",
    "     'dismissals_30D',\n",
    "     'dismissals_90D',\n",
    "     'dismissals_300D',\n",
    "     'dismissals_1000D',\n",
    "     'dismissals_1000D_venue',\n",
    "     'boundary_count_30D',\n",
    "     'boundary_count_90D',\n",
    "     'boundary_count_300D',\n",
    "     'boundary_count_1000D',\n",
    "     'boundary_count_1000D_venue',\n",
    "     'six_count_30D',\n",
    "     'six_count_90D',\n",
    "     'six_count_300D',\n",
    "     'six_count_1000D',\n",
    "     'six_count_1000D_venue',\n",
    "     'batting_avg_30D',\n",
    "     'batting_avg_90D',\n",
    "     'batting_avg_300D',\n",
    "     'batting_avg_1000D',\n",
    "     'batting_avg_1000D_venue',\n",
    "     'batting_sr_30D',\n",
    "     'batting_sr_90D',\n",
    "     'batting_sr_300D',\n",
    "     'batting_sr_1000D',\n",
    "     'batting_sr_1000D_venue',\n",
    "     'total_runs_30D',\n",
    "     'total_runs_90D',\n",
    "     'total_runs_300D',\n",
    "     'total_runs_1000D',\n",
    "     'total_runs_1000D_venue',\n",
    "     'deliveries_30D',\n",
    "     'deliveries_90D',\n",
    "     'deliveries_300D',\n",
    "     'deliveries_1000D',\n",
    "     'deliveries_1000D_venue',\n",
    "     'wicket_sum_30D',\n",
    "     'wicket_sum_90D',\n",
    "     'wicket_sum_300D',\n",
    "     'wicket_sum_1000D',\n",
    "     'wicket_sum_1000D_venue',\n",
    "     'maiden_count_30D',\n",
    "     'maiden_count_90D',\n",
    "     'maiden_count_300D',\n",
    "     'maiden_count_1000D',\n",
    "     'maiden_count_1000D_venue',\n",
    "     'bowling_avg_30D',\n",
    "     'bowling_avg_90D',\n",
    "     'bowling_avg_300D',\n",
    "     'bowling_avg_1000D',\n",
    "     'bowling_avg_1000D_venue',\n",
    "     'bowling_sr_30D',\n",
    "     'bowling_sr_90D',\n",
    "     'bowling_sr_300D',\n",
    "     'bowling_sr_1000D',\n",
    "     'bowling_sr_1000D_venue',\n",
    "     'bowling_eco_30D',\n",
    "     'bowling_eco_90D',\n",
    "     'bowling_eco_300D',\n",
    "     'bowling_eco_1000D',\n",
    "     'bowling_eco_1000D_venue'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed16997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abhay/work/dream11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model Training Flow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline model trained\n",
      "model saved\n",
      "loaded saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/02/25 22:21:38 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "23/02/25 22:21:38 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/02/25 22:21:38 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batter_name</th>\n",
       "      <th>batter_run_sum</th>\n",
       "      <th>balls_faced</th>\n",
       "      <th>dismissals</th>\n",
       "      <th>boundary_count</th>\n",
       "      <th>six_count</th>\n",
       "      <th>batter_runs_30D</th>\n",
       "      <th>batter_runs_90D</th>\n",
       "      <th>batter_runs_300D</th>\n",
       "      <th>batter_runs_1000D</th>\n",
       "      <th>...</th>\n",
       "      <th>fielding_wicket_sum</th>\n",
       "      <th>fielding_wicket_sum_300D</th>\n",
       "      <th>fielding_wicket_sum_1000D</th>\n",
       "      <th>player_id</th>\n",
       "      <th>dt</th>\n",
       "      <th>match_id</th>\n",
       "      <th>is_male</th>\n",
       "      <th>fantasy_points</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>ea27a674</td>\n",
       "      <td>2018-07-08</td>\n",
       "      <td>1127467</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>9.487413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>9c376401</td>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>1273721</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>9.487413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>d85b0f8b</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1195589</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>9.487413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>7fa12533</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>1233981</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>9.487413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a699488a</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>1351062</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>9.487413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d6164dc0</td>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>wi_201706</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>33.510988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8d5d991e</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>1296699</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>56.434879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94b30fa5</td>\n",
       "      <td>2018-06-23</td>\n",
       "      <td>1126722</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>16.452596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c7a995d3</td>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>1205735</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>60.595163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fe93fd9d</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>1216544</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>23.996934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   batter_name  batter_run_sum  balls_faced  dismissals  boundary_count  \\\n",
       "0         None               0            0           0               0   \n",
       "1         None               0            0           0               0   \n",
       "2         None               0            0           0               0   \n",
       "3         None               0            0           0               0   \n",
       "4         None               0            0           0               0   \n",
       "..         ...             ...          ...         ...             ...   \n",
       "95        None               0            0           0               0   \n",
       "96        None               0            0           0               0   \n",
       "97        None               0            0           0               0   \n",
       "98        None               0            0           0               0   \n",
       "99        None               0            0           0               0   \n",
       "\n",
       "    six_count  batter_runs_30D  batter_runs_90D  batter_runs_300D  \\\n",
       "0           0                0                0                 0   \n",
       "1           0                0                0                 0   \n",
       "2           0                0                0                 0   \n",
       "3           0                0                0                 0   \n",
       "4           0                0                0                 0   \n",
       "..        ...              ...              ...               ...   \n",
       "95          0                0                0                 0   \n",
       "96          0                0                0                 0   \n",
       "97          0                0                0                 0   \n",
       "98          0                0                0                 0   \n",
       "99          0                0                0                 0   \n",
       "\n",
       "    batter_runs_1000D  ...  fielding_wicket_sum  fielding_wicket_sum_300D  \\\n",
       "0                   0  ...                    1                         1   \n",
       "1                   0  ...                    3                         7   \n",
       "2                   0  ...                    1                         3   \n",
       "3                   0  ...                    1                         4   \n",
       "4                   0  ...                    1                         1   \n",
       "..                ...  ...                  ...                       ...   \n",
       "95                  0  ...                    0                         0   \n",
       "96                  0  ...                    0                         0   \n",
       "97                  0  ...                    0                         0   \n",
       "98                  0  ...                    0                         0   \n",
       "99                  0  ...                    0                         0   \n",
       "\n",
       "    fielding_wicket_sum_1000D  player_id          dt   match_id  is_male  \\\n",
       "0                          21   ea27a674  2018-07-08    1127467        1   \n",
       "1                          21   9c376401  2021-10-21    1273721        1   \n",
       "2                           4   d85b0f8b  2019-12-31    1195589        1   \n",
       "3                          11   7fa12533  2021-04-01    1233981        1   \n",
       "4                           1   a699488a  2023-01-14    1351062        1   \n",
       "..                        ...        ...         ...        ...      ...   \n",
       "95                          0   d6164dc0  2019-03-29  wi_201706        0   \n",
       "96                          0   8d5d991e  2022-02-01    1296699        1   \n",
       "97                          0   94b30fa5  2018-06-23    1126722        0   \n",
       "98                          0   c7a995d3  2019-11-09    1205735        1   \n",
       "99                          0   fe93fd9d  2020-10-25    1216544        1   \n",
       "\n",
       "    fantasy_points                                           features  \\\n",
       "0               11  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1               25  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2               11  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3               11  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4               11  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "..             ...                                                ...   \n",
       "95              33  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "96              54  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "97              31  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "98             124  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "99               4  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "    prediction  \n",
       "0     9.487413  \n",
       "1     9.487413  \n",
       "2     9.487413  \n",
       "3     9.487413  \n",
       "4     9.487413  \n",
       "..         ...  \n",
       "95   33.510988  \n",
       "96   56.434879  \n",
       "97   16.452596  \n",
       "98   60.595163  \n",
       "99   23.996934  \n",
       "\n",
       "[100 rows x 93 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from path_manager import model_train_input_path, model_test_input_path, model_train_predictions_path, model_test_predictions_path, model_pipeline_save_artifact_path\n",
    "\n",
    "train_df = spark.read.parquet(model_train_input_path)\n",
    "test_df = spark.read.parquet(model_test_input_path)\n",
    "print(\"Starting Model Training Flow\")\n",
    "# assemble features\n",
    "vector_assembler = VectorAssembler(inputCols = features, outputCol='features')\n",
    "# GBT regressor\n",
    "gbt_regressor = GBTRegressor(featuresCol='features', labelCol='fantasy_points', maxIter=10)\n",
    "# create Pipeline\n",
    "pipeline = Pipeline(stages = [vector_assembler, gbt_regressor])\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "print(\"Pipeline model trained\")\n",
    "# save model\n",
    "pipeline_model.write().overwrite().save(model_pipeline_save_artifact_path)\n",
    "\n",
    "print(\"model saved\")\n",
    "\n",
    "# load saved model\n",
    "loaded_pipeline_model = PipelineModel.load(model_pipeline_save_artifact_path)\n",
    "\n",
    "print(\"loaded saved model\")\n",
    "\n",
    "# assemble test features and predict on test data\n",
    "test_predictions = loaded_pipeline_model.transform(test_df)\n",
    "test_predictions.limit(100).toPandas()\n",
    "\n",
    "# # write predictions to disk\n",
    "# print(\"writing predictions over test input data to disk\")\n",
    "# test_predictions.write.format(\"parquet\").partitionBy([\"dt\"]).mode(\"overwrite\").save(model_test_predictions_path)\n",
    "\n",
    "# print(\"writing predictions over train input data to disk\")\n",
    "# train_predictions.write.format(\"parquet\").partitionBy([\"dt\"]).mode(\"overwrite\").save(model_train_predictions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579d55df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/abhay/work/dream11/model_data/models/GbtRegressionPipelinePMML/v1/dream11_v1.pmml'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from path_manager import model_pipeline_save_artifact_path, model_pipeline_pmml_save_artifact_path\n",
    "from pyspark2pmml import PMMLBuilder\n",
    "\n",
    "pmmlBuilder = PMMLBuilder(spark, train_df, loaded_pipeline_model)\n",
    "\n",
    "pmmlBuilder.buildFile(model_pipeline_pmml_save_artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f67a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
